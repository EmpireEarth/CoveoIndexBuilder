{
    "title" : "Sitemap vs. Web Connector",
    "uri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "printableUri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "clickUri" : "https://na61.salesforce.com/kA132000000081E",
    "uniqueId" : "42.13819$http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "excerpt" : "What is the difference between the web crawler and the sitemap connector? ... Why would I choose the web crawler over the sitemap connector, or visa versa? ... Why are web crawler refreshes slower ...",
    "firstSentences" : null,
    "summary" : null,
    "flags" : "HasHtmlVersion",
    "hasHtmlVersion" : true,
    "hasMobileHtmlVersion" : false,
    "score" : 1397,
    "percentScore" : 84.103615,
    "rankingInfo" : null,
    "rating" : 3.0,
    "isTopResult" : false,
    "isRecommendation" : false,
    "titleHighlights" : [ ],
    "firstSentencesHighlights" : [ ],
    "excerptHighlights" : [ ],
    "printableUriHighlights" : [ ],
    "summaryHighlights" : [ ],
    "parentResult" : null,
    "childResults" : [ ],
    "totalNumberOfChildResults" : 0,
    "raw" : {
      "systitle" : "Sitemap vs. Web Connector",
      "sfsummary" : "Explore the differences between the web crawler connector and the sitemap connector.",
      "sysurihash" : "zlcZlcHVdRvDyPfm",
      "urihash" : "zlcZlcHVdRvDyPfm",
      "parents" : "<?xml version=\"1.0\" encoding=\"utf-16\"?><parents><parent name=\"Organization\" uri=\"https://na61.salesforce.com/home/home.jsp\" /><parent name=\"KB_Article__ka\" uri=\"http://www.salesforce.com/org:organization/articletype:KB_Article\" /><parent name=\"Sitemap vs. Web Connector\" uri=\"https://na61.salesforce.com/kA132000000081E\" /></parents>",
      "sfdcarticletype" : "How To/Question",
      "sfresolutionc" : "Sitemap is kind of like a metadata layer on top of a web site or set of web sites. For the detailed specification, check out <a href=\"http://sitemaps.org\" target=\"_blank\">http://sitemaps.org</a>.<br><br>With a basic web crawler, the idea is that you give the crawler a starting page or set of pages, and the starting page(s) are indexed, links within the pages are identified and crawled, and the process repeats itself ad infinitum until all linked pages are crawled. Any page linked from your start pages, or linked from pages that are linked from the starter pages, and so on--child, grandchild, great-grandchild, etc...--are all indexed and potentially become springboards for other pages to be indexed. Any page in a site which does not somehow have a link path from the starting page(s) won&#39;t get indexed.<br><br>Finally, a web server is not very smart about its content. If you ask for a particular page, the server will feed it out to you, including metadata like last-modified-date (LMD) and so on, but it&#39;s not like a Salesforce table or an Oracle DB, where you can query for specific page types. You can&#39;t say to a web server, &quot;Give me all the pages that have been modified in the last 24 hours.&quot; Instead, what the web connector&#39;s &quot;rescan&quot; function does is that it goes through everything in the associated source, and sends the web server a &quot;HEAD&quot; request, for which the response will tell us if the file still exists, and what the last modified date is, among other things. If the file is gone, we remove it from the index. If it&#39;s there, we compare the LMD to the LMD we have on file, and if it&#39;s newer in the system of record, we send a &quot;GET&quot; request to pull the whole file and re-index it, including crawling any new links that may have been added.<br><br>This is why a web connector&#39;s &quot;rescan&quot; is faster than a full &quot;rebuild&quot;--it doesn&#39;t necessarily crawl each and every file--but it&#39;s not as fast as, say, a &quot;refresh&quot; in Salesforce, which is purely an incremental pull.<br><br>So the difference with sitemap is that instead of giving a web page that leads you to pages which lead you to pages which lead you to pages which lead you to pages, a sitemap file is a concise file (or small set of files) which includes references to the URLs of ALL the files you want to index. It can also include metadata, such as LMD, so that the Sitemap connector can do a true refresh instead of full rescan.<br><br>So if a file is updated, the site manager (or a system implemented by that site manager locally) should update the sitemap file to include an updated entry for that file, and when the connector refreshes, it pulls down the whole sitemap file, and looks for entries that are new or updated. Then it indexes the contents of the files at the URLs associated with those new or updated entries.<br><br>It doesn&#39;t ask for any information about pages whose sitemap entries are not updated, nor does it crawl any links on the pages it indexes. A web site with 100,000 documents which has a well maintained sitemap file will only take a couple of minutes to refresh if only a few pages have changed. That same site being refreshed with a regular crawler will take hours or days to do the same thing, depending on the performance of the server, as each page needs to be queried.<br><br>Last, but not least, we&#39;ve made an extension to the Sitemap standard so that clients can easily add metadata to their web content without modifying the actual web pages. It is  a powerful and flexible tool.<br><br>In short, the web crawler crawls sites driven by web servers, which are not intelligent tools by design; as such, the crawler is a sort of brute force tool. Sitemap adds an layer of intelligence to any web site; it requires more work on the client side to be effective, but it makes for a much faster and more flexible indexing experience. If the added work of implementing and maintaining a sitemap file is an option, we strongly recommend that over a basic web crawl.",
      "sysuri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
      "sysprintableuri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
      "sflastpublisheddate" : 1497458761000,
      "systransactionid" : 161139,
      "sfurlname" : "2297",
      "sfsystemmodstamp" : 1517572013000,
      "sfisvisibleinapp" : "true",
      "sysconcepts" : "web crawler ; sitemaps ; metadata ; Salesforce ; layer ; entries ; rescan ; clients ; indexing experience ; incremental pull ; extension ; references",
      "sfkbversionnumber" : "1",
      "concepts" : "web crawler ; sitemaps ; metadata ; Salesforce ; layer ; entries ; rescan ; clients ; indexing experience ; incremental pull ; extension ; references",
      "printableuri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
      "documenttype" : "article",
      "sfkbarticlekavid" : "ka1320000000FghAAE",
      "sysindexeddate" : 1518187572000,
      "sfknowledgearticleid" : "kA132000000081ECAQ",
      "sfcreatedbyid" : "00560000003GBDeAAO",
      "sfconnectorc" : "N/A",
      "permanentid" : "37215fbf55d76d1e7958276366b3fdb85ca0fd8627a59a5da31300370320",
      "syslanguage" : [ "English" ],
      "transactionid" : 161139,
      "sfisvisibleinprm" : "true",
      "title" : "Sitemap vs. Web Connector",
      "sfversionnumber" : 1,
      "sfarticlenumber" : "000002297",
      "date" : 1517572013000,
      "objecttype" : "KB Article",
      "allmetadatavalues" : "{\"kav_lastmodifiedby.attribute.type\": [\"User\"], \"coveo_short_id\": [\"kA132000000081E\"], \"sflastmodifiedbyname\": [\"Laurel Poertner\"], \"kav_coveo_version__c__html_stripped\": [\"\"], \"fileextension\": [\"\"], \"sfdcexpandedproduct\": [\"All;All|Cloud Platform;All|Cloud Services;All|Coveo Enterprise Search\"], \"kav_createdby.attribute.url\": [\"/services/data/v34.0/sobjects/User/00560000003GBDeAAO\"], \"sflanguage\": [\"en_US\"], \"kav_createdby.attribute.type\": [\"User\"], \"kav_createdby.id\": [\"00560000003GBDeAAO\"], \"kav_language\": [\"en_US\"], \"sfsitecoreversionc\": [\"N/A\"], \"sourcetype\": [\"Salesforce\"], \"title\": [\"Sitemap vs. Web Connector\"], \"source\": [\"Salesforce Public Items\"], \"kav_owner.attribute.url\": [\"/services/data/v34.0/sobjects/User/00560000003GBDeAAO\"], \"parents\": [\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-16\\\"?><parents><parent name=\\\"Organization\\\" uri=\\\"https://na61.salesforce.com/home/home.jsp\\\" /><parent name=\\\"KB_Article__ka\\\" uri=\\\"http://www.salesforce.com/org:organization/articletype:KB_Article\\\" /><parent name=\\\"Sitemap vs. Web Connector\\\" uri=\\\"https://na61.salesforce.com/kA132000000081E\\\" /></parents>\"], \"sfisvisibleinprm\": [true], \"kav_title\": [\"Sitemap vs. Web Connector\"], \"kav_isvisibleincsp\": [true], \"sfcreateddate\": [1494451925], \"hashtmlversion\": [true], \"kav_versionnumber\": [1], \"sfcreatedbyname\": [\"Benjamin Carroll\"], \"sflastpublisheddate\": [1497458761], \"objecttypelabel\": [\"KB Article\"], \"kav_cause__c__html_stripped\": [\"\"], \"originalhtmlcharset\": [1200], \"coveo_connector_hasbinarydata\": [false], \"kav_lastpublisheddate\": [1497458761], \"sfsystemmodstamp\": [1517572013], \"ka_attribute.type\": [\"KB_Article__ka\"], \"sfdcproduct\": [\"Cloud Platform;Cloud Services;Coveo Enterprise Search\"], \"clickableuri\": [\"https://na61.salesforce.com/kA132000000081E\"], \"sftitle\": [\"Sitemap vs. Web Connector\"], \"kav_owner.id\": [\"00560000003GBDeAAO\"], \"sfisvisibleinapp\": [true], \"ka_attribute.url\": [\"/services/data/v34.0/sobjects/KB_Article__ka/kA132000000081ECAQ\"], \"sfdcarticletype\": [\"How To/Question\"], \"sfislatestversion\": [true], \"sfarticlenumber\": [\"000002297\"], \"contenttype\": [\"binarydata\"], \"sfurlname\": [\"2297\"], \"ka_id\": [\"kA132000000081ECAQ\"], \"kav_datacategoryselections.datacategoryname\": [\"Coveo_Enterprise_Search;Cloud_Platform;Cloud_Services;How_To\"], \"coveo_url\": [\"https://na61.salesforce.com/kA132000000081E\"], \"kav_urlname\": [\"2297\"], \"kav_dc_expanded_product\": [\"All;All|Cloud Platform;All|Cloud Services;All|Coveo Enterprise Search\"], \"foldingcollection\": [\"d27bcc2d971b824815c183fdc1f293f92baf7b2335b2b5b3252025521535\"], \"body\": [\"<html>   <body>     <div style=\\\"background-color: #fff;border: 2px solid #BBC5CC;border-radius: 4px;float: left;font-family: lato;margin-left: 15px;margin-right: 15px;margin-bottom: 4%;padding: 10px;width: 60%;\\\">       <div style=\\\"font-size: 1.5em;font-weight: 600;Padding-top: 30px;border-bottom: 1px solid #BBC5CC;\\\">         <div style=\\\"border-left: 1px solid #BBC5CC;border-top: 1px solid #BBC5CC;color: #296896;padding: 10px;width: 15%;\\\">           Description         </div>       </div>       <div style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;\\\"> What is the difference between the web crawler and the sitemap connector?<br><br>Why would I choose the web crawler over the sitemap connector, or visa versa?<br><br>Why are web crawler refreshes slower than refreshes in Salesforce, and how can I speed them up?</div>       <div style=\\\"font-size: 1.5em;font-weight: 600;Padding-top: 30px;border-bottom: 1px solid #BBC5CC;\\\">         <div style=\\\"border-left: 1px solid #BBC5CC;border-top: 1px solid #BBC5CC;color: #296896;padding: 10px;width: 15%;\\\">           Environment         </div>       </div>       <br/>       <table>         <tr>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Product</td>           <td></td>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Sitecore Version</td>           <td>N/A</td>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Connector</td>           <td>N/A</td>         </tr>         <tr>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Published</td>           <td>1497458761</td>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Version</td>           <td></td>           <td style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;font-weight: 600;\\\">Build</td>           <td></td>         </tr>       </table>       <br/>       <div style=\\\"font-size: 1.5em;font-weight: 600;Padding-top: 30px;border-bottom: 1px solid #BBC5CC;\\\">         <div style=\\\"border-left: 1px solid #BBC5CC;border-top: 1px solid #BBC5CC;color: #296896;padding: 10px;width: 15%;\\\">           Cause         </div>       </div>       <div style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;\\\"> </div>       <div style=\\\"font-size: 1.5em;font-weight: 600;Padding-top: 30px;border-bottom: 1px solid #BBC5CC;\\\">         <div style=\\\"border-left: 1px solid #BBC5CC;border-top: 1px solid #BBC5CC;color: #296896;padding: 10px;width: 15%;\\\">           Resolution         </div>       </div>       <div style=\\\"margin-left: 35px;margin-top: 10px;font-size: 1em;\\\"> Sitemap is kind of like a metadata layer on top of a web site or set of web sites. For the detailed specification, check out <a href=\\\"http://sitemaps.org\\\" target=\\\"_blank\\\">http://sitemaps.org</a>.<br><br>With a basic web crawler, the idea is that you give the crawler a starting page or set of pages, and the starting page(s) are indexed, links within the pages are identified and crawled, and the process repeats itself ad infinitum until all linked pages are crawled.\\u00a0Any page linked from your start pages, or linked from pages that are linked from the starter pages, and so on--child, grandchild, great-grandchild, etc...--are all indexed and potentially become springboards for other pages to be indexed.\\u00a0Any page in a site which does not somehow have a link path from the starting page(s) won&#39;t get indexed.<br><br>Finally, a web server is not very smart about its content. If you ask for a particular page, the server will feed it out to you, including metadata like last-modified-date (LMD) and so on, but it&#39;s not like a Salesforce table or an Oracle DB, where you can query for specific page types. You can&#39;t say to a web server, &quot;Give me all the pages that have been modified in the last 24 hours.&quot; Instead, what the web connector&#39;s &quot;rescan&quot; function does is that it goes through everything in the associated source, and sends the web server a &quot;HEAD&quot; request, for which the response will tell us if the file still exists, and what the last modified date is, among other things. If the file is gone, we remove it from the index. If it&#39;s there, we compare the LMD to the LMD we have on file, and if it&#39;s newer in the system of record, we send a &quot;GET&quot; request to pull the whole file and re-index it, including crawling any new links that may have been added.<br><br>This is why a web connector&#39;s &quot;rescan&quot; is faster than a full &quot;rebuild&quot;--it doesn&#39;t necessarily crawl each and every file--but it&#39;s not as fast as, say, a &quot;refresh&quot; in Salesforce, which is purely an incremental pull.<br><br>So the difference with sitemap is that instead of giving a web page that leads you to pages which lead you to pages which lead you to pages\\u00a0which lead you to pages, a sitemap file is a concise file (or small set of files) which includes references to the URLs of ALL the files you want to index. It can also include metadata, such as LMD, so that the Sitemap connector can do a true refresh instead of full rescan.<br><br>So if a file is updated, the site manager (or a system implemented by that site manager locally) should update the sitemap file to include an updated entry for that file, and when the connector refreshes, it pulls down the whole sitemap file, and looks for entries that are new or updated.\\u00a0Then it indexes the contents of the files at the URLs associated with those new or updated entries.<br><br>It doesn&#39;t ask for any information about pages whose sitemap entries are not updated, nor does it crawl any links on the pages it indexes. A web site with 100,000 documents which has a well maintained sitemap file will only take a couple of minutes to refresh if only a few pages have changed. That same site being refreshed with a regular crawler will take hours or days to do the same thing, depending on the performance of the server, as each page needs to be queried.<br><br>Last, but not least, we&#39;ve made an extension to the Sitemap standard so that clients can easily add metadata to their web content without modifying the actual web pages. It is \\u00a0a powerful and flexible tool.<br><br>In short, the web crawler crawls sites driven by web servers, which are not intelligent tools by design; as such, the crawler is a sort of brute force tool. Sitemap adds an layer of intelligence to any web site; it requires more work on the client side to be effective, but it makes for a much faster and more flexible indexing experience. If the added work of implementing and maintaining a sitemap file is an option, we strongly recommend that over a basic web crawl.</div>     </div>   </body> </html>\"], \"sfpublishstatus\": [\"Online\"], \"sfcreatedbyid\": [\"00560000003GBDeAAO\"], \"kav_description__c__html_stripped\": [\"What is the difference between the web crawler and the sitemap connector? \\n \\n Why would I choose the web crawler over the sitemap connector, or visa versa? \\n \\n Why are web crawler refreshes slower than refreshes in Salesforce, and how can I speed them up?\"], \"kav_islatestversion\": [true], \"kav_knowledgearticleid\": [\"kA132000000081ECAQ\"], \"sfknowledgearticleid\": [\"kA132000000081ECAQ\"], \"sfownername\": [\"Benjamin Carroll\"], \"kav_datacategoryselections.attribute.type\": [\"KB_Article__DataCategorySelection;KB_Article__DataCategorySelection;KB_Article__DataCategorySelection;KB_Article__DataCategorySelection\"], \"detectedtitle\": [\"Description\"], \"kav_createddate\": [1494451925], \"language\": [\"English\"], \"coveo_foldingchild\": [\"6c6c944165d8eb8a71eef03ac422e7e5ea0363432794927f41e25e9c9cf8\"], \"sfownerid\": [\"00560000003GBDeAAO\"], \"kav_createdby.coveo_record_size\": [2], \"kav_systemmodstamp\": [1517572013], \"objecttype\": [\"KB Article\"], \"connectortype\": [\"Salesforce2\"], \"kav_coveo_record_size\": [4], \"originaluri\": [\"http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US\"], \"sfisvisibleincsp\": [true], \"convertertype\": [\"TYPE_HTML\"], \"filetype\": [\"SalesforceItem\"], \"kav_owner.name\": [\"Benjamin Carroll\"], \"sfdcexpandedarticletype\": [\"All;All|How To/Question\"], \"objecttypelabelplural\": [\"KB Articles\"], \"sfcurrencyisocode\": [\"USD\"], \"sfisdeleted\": [false], \"extractedsize\": [8546], \"size\": [11202], \"kav_summary\": [\"Explore the differences between the web crawler connector and the sitemap connector.\"], \"kav_publishstatus\": [\"Online\"], \"kav_connector__c\": [\"N/A\"], \"generateexcerpt\": [true], \"sfdescriptionc\": [\"What is the difference between the web crawler and the sitemap connector?<br><br>Why would I choose the web crawler over the sitemap connector, or visa versa?<br><br>Why are web crawler refreshes slower than refreshes in Salesforce, and how can I speed them up?\"], \"sfarticletype\": [\"KB_Article__kav\"], \"kav_lastmodifieddate\": [1497458761], \"documenttype\": [\"article\"], \"sfkbarticlekavid\": [\"ka1320000000FghAAE\"], \"kav_currencyisocode\": [\"USD\"], \"foldingparent\": [\"6c6c944165d8eb8a71eef03ac422e7e5ea0363432794927f41e25e9c9cf8\"], \"mappingtype\": [\"KB_Article\"], \"kav_isvisibleinpkb\": [true], \"sfkbversionnumber\": [1], \"kav_isvisibleinapp\": [true], \"kav_resolution__c\": [\"Sitemap is kind of like a metadata layer on top of a web site or set of web sites. For the detailed specification, check out <a href=\\\"http://sitemaps.org\\\" target=\\\"_blank\\\">http://sitemaps.org</a>.<br><br>With a basic web crawler, the idea is that you give the crawler a starting page or set of pages, and the starting page(s) are indexed, links within the pages are identified and crawled, and the process repeats itself ad infinitum until all linked pages are crawled.\\u00a0Any page linked from your start pages, or linked from pages that are linked from the starter pages, and so on--child, grandchild, great-grandchild, etc...--are all indexed and potentially become springboards for other pages to be indexed.\\u00a0Any page in a site which does not somehow have a link path from the starting page(s) won&#39;t get indexed.<br><br>Finally, a web server is not very smart about its content. If you ask for a particular page, the server will feed it out to you, including metadata like last-modified-date (LMD) and so on, but it&#39;s not like a Salesforce table or an Oracle DB, where you can query for specific page types. You can&#39;t say to a web server, &quot;Give me all the pages that have been modified in the last 24 hours.&quot; Instead, what the web connector&#39;s &quot;rescan&quot; function does is that it goes through everything in the associated source, and sends the web server a &quot;HEAD&quot; request, for which the response will tell us if the file still exists, and what the last modified date is, among other things. If the file is gone, we remove it from the index. If it&#39;s there, we compare the LMD to the LMD we have on file, and if it&#39;s newer in the system of record, we send a &quot;GET&quot; request to pull the whole file and re-index it, including crawling any new links that may have been added.<br><br>This is why a web connector&#39;s &quot;rescan&quot; is faster than a full &quot;rebuild&quot;--it doesn&#39;t necessarily crawl each and every file--but it&#39;s not as fast as, say, a &quot;refresh&quot; in Salesforce, which is purely an incremental pull.<br><br>So the difference with sitemap is that instead of giving a web page that leads you to pages which lead you to pages which lead you to pages\\u00a0which lead you to pages, a sitemap file is a concise file (or small set of files) which includes references to the URLs of ALL the files you want to index. It can also include metadata, such as LMD, so that the Sitemap connector can do a true refresh instead of full rescan.<br><br>So if a file is updated, the site manager (or a system implemented by that site manager locally) should update the sitemap file to include an updated entry for that file, and when the connector refreshes, it pulls down the whole sitemap file, and looks for entries that are new or updated.\\u00a0Then it indexes the contents of the files at the URLs associated with those new or updated entries.<br><br>It doesn&#39;t ask for any information about pages whose sitemap entries are not updated, nor does it crawl any links on the pages it indexes. A web site with 100,000 documents which has a well maintained sitemap file will only take a couple of minutes to refresh if only a few pages have changed. That same site being refreshed with a regular crawler will take hours or days to do the same thing, depending on the performance of the server, as each page needs to be queried.<br><br>Last, but not least, we&#39;ve made an extension to the Sitemap standard so that clients can easily add metadata to their web content without modifying the actual web pages. It is \\u00a0a powerful and flexible tool.<br><br>In short, the web crawler crawls sites driven by web servers, which are not intelligent tools by design; as such, the crawler is a sort of brute force tool. Sitemap adds an layer of intelligence to any web site; it requires more work on the client side to be effective, but it makes for a much faster and more flexible indexing experience. If the added work of implementing and maintaining a sitemap file is an option, we strongly recommend that over a basic web crawl.\"], \"coveo_objecttype\": [\"KB_Article\"], \"printableuri\": [\"http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US\"], \"kav_datacategoryselections.attribute.url\": [\"/services/data/v34.0/sobjects/KB_Article__DataCategorySelection/02o320000004c4gAAA;/services/data/v34.0/sobjects/KB_Article__DataCategorySelection/02o320000004adPAAQ;/services/data/v34.0/sobjects/KB_Article__DataCategorySelection/02o320000004adOAAQ;/services/data/v34.0/sobjects/KB_Article__DataCategorySelection/02o320000004c4hAAA\"], \"kav_id\": [\"ka1320000000FghAAE\"], \"sfresolutionc\": [\"Sitemap is kind of like a metadata layer on top of a web site or set of web sites. For the detailed specification, check out <a href=\\\"http://sitemaps.org\\\" target=\\\"_blank\\\">http://sitemaps.org</a>.<br><br>With a basic web crawler, the idea is that you give the crawler a starting page or set of pages, and the starting page(s) are indexed, links within the pages are identified and crawled, and the process repeats itself ad infinitum until all linked pages are crawled.\\u00a0Any page linked from your start pages, or linked from pages that are linked from the starter pages, and so on--child, grandchild, great-grandchild, etc...--are all indexed and potentially become springboards for other pages to be indexed.\\u00a0Any page in a site which does not somehow have a link path from the starting page(s) won&#39;t get indexed.<br><br>Finally, a web server is not very smart about its content. If you ask for a particular page, the server will feed it out to you, including metadata like last-modified-date (LMD) and so on, but it&#39;s not like a Salesforce table or an Oracle DB, where you can query for specific page types. You can&#39;t say to a web server, &quot;Give me all the pages that have been modified in the last 24 hours.&quot; Instead, what the web connector&#39;s &quot;rescan&quot; function does is that it goes through everything in the associated source, and sends the web server a &quot;HEAD&quot; request, for which the response will tell us if the file still exists, and what the last modified date is, among other things. If the file is gone, we remove it from the index. If it&#39;s there, we compare the LMD to the LMD we have on file, and if it&#39;s newer in the system of record, we send a &quot;GET&quot; request to pull the whole file and re-index it, including crawling any new links that may have been added.<br><br>This is why a web connector&#39;s &quot;rescan&quot; is faster than a full &quot;rebuild&quot;--it doesn&#39;t necessarily crawl each and every file--but it&#39;s not as fast as, say, a &quot;refresh&quot; in Salesforce, which is purely an incremental pull.<br><br>So the difference with sitemap is that instead of giving a web page that leads you to pages which lead you to pages which lead you to pages\\u00a0which lead you to pages, a sitemap file is a concise file (or small set of files) which includes references to the URLs of ALL the files you want to index. It can also include metadata, such as LMD, so that the Sitemap connector can do a true refresh instead of full rescan.<br><br>So if a file is updated, the site manager (or a system implemented by that site manager locally) should update the sitemap file to include an updated entry for that file, and when the connector refreshes, it pulls down the whole sitemap file, and looks for entries that are new or updated.\\u00a0Then it indexes the contents of the files at the URLs associated with those new or updated entries.<br><br>It doesn&#39;t ask for any information about pages whose sitemap entries are not updated, nor does it crawl any links on the pages it indexes. A web site with 100,000 documents which has a well maintained sitemap file will only take a couple of minutes to refresh if only a few pages have changed. That same site being refreshed with a regular crawler will take hours or days to do the same thing, depending on the performance of the server, as each page needs to be queried.<br><br>Last, but not least, we&#39;ve made an extension to the Sitemap standard so that clients can easily add metadata to their web content without modifying the actual web pages. It is \\u00a0a powerful and flexible tool.<br><br>In short, the web crawler crawls sites driven by web servers, which are not intelligent tools by design; as such, the crawler is a sort of brute force tool. Sitemap adds an layer of intelligence to any web site; it requires more work on the client side to be effective, but it makes for a much faster and more flexible indexing experience. If the added work of implementing and maintaining a sitemap file is an option, we strongly recommend that over a basic web crawl.\"], \"foldingchild\": [\"6c6c944165d8eb8a71eef03ac422e7e5ea0363432794927f41e25e9c9cf8\"], \"sfsummary\": [\"Explore the differences between the web crawler connector and the sitemap connector.\"], \"kav_sitecore_version__c\": [\"N/A\"], \"kav_owner.coveo_record_size\": [2], \"kav_coveo_effective_modstamp\": [1517572013], \"kav_summary__html_stripped\": [\"Explore the differences between the web crawler connector and the sitemap connector.\"], \"kav_dc_article_type\": [\"How To/Question\"], \"sfconnectorc\": [\"N/A\"], \"kav_dc_product\": [\"Cloud Platform;Cloud Services;Coveo Enterprise Search\"], \"ka_coveo_record_size\": [2], \"kav_dc_expanded_article_type\": [\"All;All|How To/Question\"], \"kav_datacategoryselections.coveo_record_size\": [\"2;2;2;2\"], \"concepts\": [\"web crawler ; sitemaps ; metadata ; Salesforce ; layer ; entries ; rescan ; clients ; indexing experience ; incremental pull ; extension ; references\"], \"sfkbid\": [\"kA132000000081ECAQ\"], \"kav_firstpublisheddate\": [1497458761], \"coveo_organization_id\": [\"00D3000000007r2\"], \"coveo_foldingcollection\": [\"d27bcc2d971b824815c183fdc1f293f92baf7b2335b2b5b3252025521535\"], \"sffirstpublisheddate\": [1497458761], \"sflastmodifieddate\": [1497458761], \"kav_resolution__c__html_stripped\": [\"Sitemap is kind of like a metadata layer on top of a web site or set of web sites. For the detailed specification, check out  http://sitemaps.org . \\n \\n With a basic web crawler, the idea is that you give the crawler a starting page or set of pages, and the starting page(s) are indexed, links within the pages are identified and crawled, and the process repeats itself ad infinitum until all linked pages are crawled.\\u00a0Any page linked from your start pages, or linked from pages that are linked from the starter pages, and so on--child, grandchild, great-grandchild, etc...--are all indexed and potentially become springboards for other pages to be indexed.\\u00a0Any page in a site which does not somehow have a link path from the starting page(s) won't get indexed. \\n \\n Finally, a web server is not very smart about its content. If you ask for a particular page, the server will feed it out to you, including metadata like last-modified-date (LMD) and so on, but it's not like a Salesforce table or an Oracle DB, where you can query for specific page types. You can't say to a web server, \\\"Give me all the pages that have been modified in the last 24 hours.\\\" Instead, what the web connector's \\\"rescan\\\" function does is that it goes through everything in the associated source, and sends the web server a \\\"HEAD\\\" request, for which the response will tell us if the file still exists, and what the last modified date is, among other things. If the file is gone, we remove it from the index. If it's there, we compare the LMD to the LMD we have on file, and if it's newer in the system of record, we send a \\\"GET\\\" request to pull the whole file and re-index it, including crawling any new links that may have been added. \\n \\n This is why a web connector's \\\"rescan\\\" is faster than a full \\\"rebuild\\\"--it doesn't necessarily crawl each and every file--but it's not as fast as, say, a \\\"refresh\\\" in Salesforce, which is purely an incremental pull. \\n \\n So the difference with sitemap is that instead of giving a web page that leads you to pages which lead you to pages which lead you to pages\\u00a0which lead you to pages, a sitemap file is a concise file (or small set of files) which includes references to the URLs of ALL the files you want to index. It can also include metadata, such as LMD, so that the Sitemap connector can do a true refresh instead of full rescan. \\n \\n So if a file is updated, the site manager (or a system implemented by that site manager locally) should update the sitemap file to include an updated entry for that file, and when the connector refreshes, it pulls down the whole sitemap file, and looks for entries that are new or updated.\\u00a0Then it indexes the contents of the files at the URLs associated with those new or updated entries. \\n \\n It doesn't ask for any information about pages whose sitemap entries are not updated, nor does it crawl any links on the pages it indexes. A web site with 100,000 documents which has a well maintained sitemap file will only take a couple of minutes to refresh if only a few pages have changed. That same site being refreshed with a regular crawler will take hours or days to do the same thing, depending on the performance of the server, as each page needs to be queried. \\n \\n Last, but not least, we've made an extension to the Sitemap standard so that clients can easily add metadata to their web content without modifying the actual web pages. It is \\u00a0a powerful and flexible tool. \\n \\n In short, the web crawler crawls sites driven by web servers, which are not intelligent tools by design; as such, the crawler is a sort of brute force tool. Sitemap adds an layer of intelligence to any web site; it requires more work on the client side to be effective, but it makes for a much faster and more flexible indexing experience. If the added work of implementing and maintaining a sitemap file is an option, we strongly recommend that over a basic web crawl.\"], \"kav_vendor_version__c__html_stripped\": [\"\"], \"detectedlanguage\": [1], \"kav_isvisibleinprm\": [true], \"kav_owner.attribute.type\": [\"Name\"], \"kav_lastmodifiedby.attribute.url\": [\"/services/data/v34.0/sobjects/User/00532000005IZovAAG\"], \"sitename\": [\"Community\"], \"kav_createdby.name\": [\"Benjamin Carroll\"], \"kav_lastmodifiedby.coveo_record_size\": [2], \"sfisvisibleinpkb\": [true], \"kav_datacategoryselections.id\": [\"02o320000004c4gAAA;02o320000004adPAAQ;02o320000004adOAAQ;02o320000004c4hAAA\"], \"kav_description__c\": [\"What is the difference between the web crawler and the sitemap connector?<br><br>Why would I choose the web crawler over the sitemap connector, or visa versa?<br><br>Why are web crawler refreshes slower than refreshes in Salesforce, and how can I speed them up?\"], \"kav_validationstatus\": [\"Work In Progress\"], \"kav_attribute.url\": [\"/services/data/v34.0/sobjects/KB_Article__kav/ka1320000000FghAAE\"], \"kav_articlenumber__stripped\": [\"2297\"], \"sfversionnumber\": [1], \"kav_attribute.type\": [\"KB_Article__kav\"], \"kav_articletype\": [\"KB_Article__kav\"], \"coveo_foldingparent\": [\"6c6c944165d8eb8a71eef03ac422e7e5ea0363432794927f41e25e9c9cf8\"], \"collection\": [\"default\"], \"date\": [1517572013], \"kav_lastmodifiedby.id\": [\"00532000005IZovAAG\"], \"kav_datacategoryselections.datacategorygroupname\": [\"Product;Product;Product;Article_Type\"], \"conversionstate\": [0], \"sfvalidationstatus\": [\"Work In Progress\"], \"kav_isdeleted\": [false], \"sflastmodifiedbyid\": [\"00532000005IZovAAG\"], \"kav_lastmodifiedby.name\": [\"Laurel Poertner\"], \"kav_articlenumber\": [\"000002297\"], \"permanentid\": [\"37215fbf55d76d1e7958276366b3fdb85ca0fd8627a59a5da31300370320\"]}",
      "sflastmodifiedbyid" : "00532000005IZovAAG",
      "syssfownerid" : "00560000003GBDeAAO",
      "sfsitecoreversionc" : "N/A",
      "sourcetype" : "Salesforce",
      "sysconnectortype" : "Salesforce2",
      "sftitle" : "Sitemap vs. Web Connector",
      "rowid" : 5492896,
      "syssfcreatedbyid" : "00560000003GBDeAAO",
      "sfdescriptionc" : "What is the difference between the web crawler and the sitemap connector?<br><br>Why would I choose the web crawler over the sitemap connector, or visa versa?<br><br>Why are web crawler refreshes slower than refreshes in Salesforce, and how can I speed them up?",
      "size" : 11202,
      "sfislatestversion" : "true",
      "sysdocumenttype" : "article",
      "sfcreateddate" : 1494451925000,
      "clickableuri" : "https://na61.salesforce.com/kA132000000081E",
      "syssource" : "Salesforce Public Items",
      "sfownerid" : "00560000003GBDeAAO",
      "orderingid" : 212384990660371676,
      "sfpublishstatus" : "Online",
      "syssize" : 11202,
      "sysdate" : 1517572013000,
      "sflanguage" : "en_US",
      "sysparents" : "<?xml version=\"1.0\" encoding=\"utf-16\"?><parents><parent name=\"Organization\" uri=\"https://na61.salesforce.com/home/home.jsp\" /><parent name=\"KB_Article__ka\" uri=\"http://www.salesforce.com/org:organization/articletype:KB_Article\" /><parent name=\"Sitemap vs. Web Connector\" uri=\"https://na61.salesforce.com/kA132000000081E\" /></parents>",
      "sfdcexpandedarticletype" : "All;All|How To/Question",
      "sfcurrencyisocode" : "USD",
      "sfkbid" : "kA132000000081ECAQ",
      "sfdcexpandedproduct" : "All;All|Cloud Platform;All|Cloud Services;All|Coveo Enterprise Search",
      "syssfcreateddate" : 1494451925000,
      "sflastmodifieddate" : 1497458761000,
      "sfisvisibleinpkb" : "true",
      "source" : "Salesforce Public Items",
      "sfisdeleted" : "false",
      "sfisvisibleincsp" : "true",
      "sfvalidationstatus" : "Work In Progress",
      "sflastmodifiedbyname" : "Laurel Poertner",
      "collection" : "default",
      "sfdcproduct" : [ "Cloud Platform", "Cloud Services", "Coveo Enterprise Search" ],
      "syssourcetype" : "Salesforce",
      "sfarticletype" : "KB_Article__kav",
      "indexeddate" : 1518187572000,
      "connectortype" : "Salesforce2",
      "filetype" : "SalesforceItem",
      "sfcreatedbyname" : "Benjamin Carroll",
      "sysclickableuri" : "https://na61.salesforce.com/kA132000000081E",
      "sysfiletype" : "SalesforceItem",
      "language" : [ "English" ],
      "sffirstpublisheddate" : 1497458761000,
      "sfownername" : "Benjamin Carroll",
      "sitename" : "Community",
      "sysrowid" : 5492896,
      "uri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
      "syscollection" : "default"
    },
    "Title" : "Sitemap vs. Web Connector",
    "Uri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "PrintableUri" : "http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "ClickUri" : "https://na61.salesforce.com/kA132000000081E",
    "UniqueId" : "42.13819$http://www.salesforce.com/org:organization/articletype:KB_Article/article:kA132000000081ECAQ/language:en_US",
    "Excerpt" : "What is the difference between the web crawler and the sitemap connector? ... Why would I choose the web crawler over the sitemap connector, or visa versa? ... Why are web crawler refreshes slower ...",
    "FirstSentences" : null
  }